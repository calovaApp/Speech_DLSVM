{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "import tflearn\n",
    "from python_speech_features import fbank\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tflearn.data_utils import shuffle, to_categorical\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.metrics import Accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mfsc(signal, samplerate):\n",
    "    feat, energy = fbank(signal, samplerate)\n",
    "    feat = np.log(feat)\n",
    "\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#parah datanya walau length nya sama2 6 seconds, matrix length nya berbeda, jadi harus entah diganti datasetnya\n",
    "#atau di potong semua datanya supaya sama\n",
    "#ternyata kalo di potong pake udacity dengan length yang sama baru bisa bener ukuran size nya (shape)\n",
    "[fs1,signal1] = scipy.io.wavfile.read('commands/c10r5.wav')\n",
    "[fs2,signal2] = scipy.io.wavfile.read('commands/c10r6.wav')\n",
    "static1 = mfsc(signal1, fs1)\n",
    "static2 = mfsc(signal2, fs2)\n",
    "print(static1.shape)\n",
    "print(static2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_delta(inp):\n",
    "    delta = np.zeros(inp.shape)\n",
    "    for i in xrange(inp[0,].size):\n",
    "        coef = i\n",
    "        if coef == 0:\n",
    "            bef = inp[i,coef]\n",
    "            #print('bef=0',bef)\n",
    "        else :\n",
    "            bef = inp[i,coef-1]\n",
    "            #print('bef other 0',bef)\n",
    "    \n",
    "        if coef == (inp[0].size)-1:\n",
    "            af = inp[i,coef]\n",
    "            #print('af at 25',af)\n",
    "        else :\n",
    "            af = inp[i,coef+1]\n",
    "            #print('af other 25', af)\n",
    "        delta[i,coef]= (af-bef)/2.0\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_inp(static, delta, ddelta):\n",
    "    input_array=np.array([static,delta,ddelta])\n",
    "    input_array = input_array.reshape(1,300,26,3)\n",
    "    return input_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/scipy/io/wavfile.py:267: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 26, 3)\n",
      "60\n",
      "[[[-14.99780464 -14.90483952 -13.72289467]\n",
      "  [-14.15871429 -13.83611107 -13.29774284]\n",
      "  [-14.07499409 -12.09693146 -11.94316769]\n",
      "  ..., \n",
      "  [-10.07998943  -9.30215645  -9.49476719]\n",
      "  [ -9.69148922  -9.90518188  -9.77798176]\n",
      "  [ -9.2341795   -9.21438313  -9.19099236]]\n",
      "\n",
      " [[-15.01362896 -14.82248402 -14.33584595]\n",
      "  [-13.74812031 -13.13830471 -14.36412907]\n",
      "  [-12.86218548 -11.78998756 -11.68475056]\n",
      "  ..., \n",
      "  [-10.63938141 -10.38736534  -9.82688618]\n",
      "  [ -9.86316299  -9.77239132  -9.76496887]\n",
      "  [ -9.49060345  -9.4951849   -9.3185997 ]]\n",
      "\n",
      " [[-14.81904888 -14.83325195 -14.92224216]\n",
      "  [-13.7584219  -12.31407356 -13.31699467]\n",
      "  [-13.29327488 -12.00440502 -11.63729095]\n",
      "  ..., \n",
      "  [-10.77215958 -10.69075966 -10.02914333]\n",
      "  [-10.42776585 -10.06092453  -9.72300148]\n",
      "  [ -9.35540676  -9.52811909  -9.31997585]]\n",
      "\n",
      " ..., \n",
      " [[  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  ..., \n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]\n",
      "\n",
      " [[  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  ..., \n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]\n",
      "\n",
      " [[  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  ..., \n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "sig_len = 300\n",
    "sig_feat = 26\n",
    "X = np.zeros((60,sig_len, sig_feat, 3), dtype='float64')\n",
    "y = np.zeros(60)\n",
    "count = 0\n",
    "\n",
    "#digit 1 and labels\n",
    "for j in range(10):\n",
    "    for i in range(6):\n",
    "        [fs,signal] = scipy.io.wavfile.read('commands/c'+str(j+1)+'r'+str(i+1)+'.wav')\n",
    "        #print(signal)\n",
    "        static = mfsc(signal, fs)\n",
    "        #print(static.shape)\n",
    "        delta = get_delta(static)\n",
    "        ddelta = get_delta(delta)\n",
    "        new_inp = reshape_inp(static, delta, ddelta)\n",
    "        X[count] = np.array(new_inp)\n",
    "        \n",
    "        y[count] = j\n",
    "        count += 1\n",
    "print(X[2].shape)\n",
    "\n",
    "#plt.imshow(X[11])\n",
    "print(len(X))\n",
    "print(X[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  9.  7.  5.  5.  1.  0.  8.  6.  5.  2.  9.]\n"
     ]
    }
   ],
   "source": [
    "#splitting dataset supaya random\n",
    "X, X_test, Y, Y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# encode the Ys\n",
    "Y = to_categorical(Y, 10)\n",
    "Y_test = to_categorical(Y_test, 10)\n",
    "\n",
    "#print(Y)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input is a 32x32 image with 3 color channels (red, green and blue)\n",
    "network = input_data(shape=[None, 300, 26, 3])\n",
    "\n",
    "conv_1 = conv_2d(network, 32, 5, activation='relu', name='conv_1')\n",
    "#pooling layer with filter size 2x2\n",
    "network = max_pool_2d(conv_1, 2)\n",
    "conv_2 = conv_2d(network, 64, 3, activation='relu', name='conv_2')\n",
    "network = max_pool_2d(conv_1, 2)\n",
    "#FC layer with number of neurons 512\n",
    "network = fully_connected(network, 512, activation='relu')\n",
    "#dropout layer to prevent overfitting\n",
    "network = dropout(network, 0.5)\n",
    "#final FC with classifier : softmax\n",
    "network = fully_connected(network, 10, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m21.38569\u001b[0m\u001b[0m | time: 4.229s\n",
      "| Adam | epoch: 010 | loss: 21.38569 - acc: 0.0712 -- iter: 40/48\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m21.64020\u001b[0m\u001b[0m | time: 6.386s\n",
      "| Adam | epoch: 010 | loss: 21.64020 - acc: 0.0602 | val_loss: 21.10703 - val_acc: 0.0833 -- iter: 48/48\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "#calculate the accuracy\n",
    "acc = Accuracy(name=\"Accuracy\")\n",
    "#define how network to be trained\n",
    "#it uses crossentropy loss function, adam optimizer for gradient descent, learning rate 0.0005 \n",
    "network = regression(network, optimizer='adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     learning_rate=0.0005)\n",
    "\n",
    "# Wrap the network in a model object\n",
    "# Train using classifier\n",
    "model = tflearn.DNN(network, tensorboard_verbose=0)\n",
    "tf.reset_default_graph()\n",
    "model.fit(X, Y, n_epoch=10, shuffle=True, validation_set=(X_test, Y_test),\n",
    "          show_metric=True, batch_size=10, run_id='speech_cnn')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "x = tf.placeholder(tf.float32, [None,None, None,3])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "           \n",
    "x2 = tf.reshape(x, [-1, 7800])           # -1 means \"all\"\n",
    "\n",
    "W = tf.Variable(tf.random_normal([7800, 10], stddev=0.35),name=\"weights\")\n",
    "b = tf.Variable(tf.zeros([10], dtype=tf.float32),  name=\"biases\")\n",
    "#inference\n",
    "y = tf.nn.softmax(tf.matmul(x2, W) + b)\n",
    "#error log\n",
    "#cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train using classifier\n",
    "model.fit(X, Y, n_epoch=10, shuffle=True, validation_set=(X_test, Y_test),\n",
    "          show_metric=True, batch_size=30, run_id='speech_cnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(y_, feed_dict={x:X,y_:Y}))\n",
    "print(y_.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "input_layer = tf.reshape(x, [-1, 300, 26, 3])\n",
    "conv1 = tf.layers.conv2d(inputs=input_layer,filters=16,kernel_size=[5, 5],padding=\"same\",activation=tf.nn.relu)\n",
    "\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "conv2 = tf.layers.conv2d(\n",
    "    inputs=pool1,\n",
    "    filters=64,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "pool2_flat = tf.reshape(pool2, [-1, 75 * 75 * 64])\n",
    "dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "dropout = tf.layers.dropout(inputs=dense, rate=0.5)\n",
    "logits = tf.layers.dense(inputs=dropout, units=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = None\n",
    "train_op = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train using classifier\n",
    "model.fit(X, Y, n_epoch=10, shuffle=True, validation_set=(X_test, Y_test),\n",
    "          show_metric=True, batch_size=10, run_id='digits_cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
